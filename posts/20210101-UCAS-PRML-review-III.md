# PRML：朴素贝叶斯和 Logistic 回归（3）

## 1. 朴素贝叶斯和 Logistic 回归、SVM 的参数比较

> 假设在给定类别的情况下，$x_1, x_2, x_3$ 是独立的随机变量，那么分类器如（Logistic 回归、SVM）会比朴素贝叶斯分类器表现更好吗？❓

## 1.1 朴素贝叶斯

朴素贝叶斯使用**极大似然估计进行参数估计**、使用**极大后验概率估计进行决策**。

✅ 朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关。由于变量独立假设，不需要计算整个协方差矩阵。

变量的独立假设在现实生活中往往是不成立的。

如果训练集中某个类别的数据 $X: \{ x_1,x_2,x_3 \}$ 没有涵盖第 $i$ 维特征 $x_i$，相应估计的条件概率 $p(x_i \mid y) = 0$、从而导致模型可能会在测试集上的分类产生误差。解决这个问题的办法是在各个估计中加入平滑项 $\lambda$，$\lambda = 1$ 即为**拉普拉斯平滑。**

在已知**独立同分布**的前提下，朴素贝叶斯分类器使用是最大后验概率（MAP）决策准则：

$$argmax_{c} \ p(C = c) \prod_{i=1}^{n} p(F_i = f_i \mid C=c)$$

### 1.2 Logistic 回归

**Logistic 回归的本质**是：假设数据服从这个分布（**Logistic 分布**是一种连续型的概率分布），然后使用极大似然估计做参数的估计。

> Logistic 分布的形状与正态分布的形状相似，但是 Logistic 分布的尾部更长，所以可以使用 Logistic 分布来建模比正态分布具有更长尾部和更高波峰的数据分布。
>
> 在深度学习中常用到的 Sigmoid 函数就是 Logistic 的分布函数的特殊形式。
>
> [Logistic 回归](https://zhuanlan.zhihu.com/p/74874291)

- Logistic 在 $w^Tx + b$ 的基础上加上一层，找到分类概率 $P(Y=1)$ 与输入向量 $x$ 的直接关系，然后通过比较概率值来判断类别。使用 $w^T x + b$ 来拟合条件概率 $P(Y=1 \mid x)$ ，对数几率函数（符合概率从 0~1 的要求）：

$$y = \frac{1}{1 + e^{-(w^T x + b)}}$$

- 化简得：

$$\Rightarrow ln(\frac{y}{1-y}) = w^T x + b$$

- $\frac{y}{1-y}$ ：正类和负类概率的比值称为几率（odds）。

$$\Rightarrow ln(odds) = ln(\frac{y}{1-y})$$

- 将 $y$ 视为后验概率

$$\Rightarrow w^Tx + b = ln\frac{P(Y=1 \mid x)}{ 1- P(Y=1 \mid x)}$$

$$\Rightarrow P(Y=1 \mid x) = \frac{1}{1 + e^{-(w^Tx+b)}}$$

即：输出 $Y=1$ 的对数几率是由输入 $x$ 的线性函数表示的模型，这就是 Logistic 回归模型。

Logistic 回归的思路是，先拟合决策边界，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。

Logistic 回归的优点：

- **直接对分类的概率建模，无需实现假设数据分布，从而避免了假设分布不准确带来的问题；**
- 不仅可预测出类别，还能得到该预测的概率，这对一些利用概率辅助决策的任务很有用；
- 对数几率函数是任意阶可导的凸函数，有许多数值优化算法都可以求出最优解。

---

⚠️ 我对 Logistic 回归一直无法理解！！！

数据是离散的，如何对数据进行拟合。拟合和分类之间的关系是什么❓

（1）如何拟合？

- 使用线性回归算法
  - 假设函数：$h_\theta (x) = \theta_0 + \theta_1 x$
  - 代价函数最小化即可：$J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)})$

（2）Logistic回归如何将回归和分类结合起来？Logistic 回归中拟合的是什么❓

- $$w^T x = log \frac{p(y = 1 \mid x)}{1 - p(y = 1 \mid x)}$$
- Logistic 回归可以看作预测值为“标签的对数几率”的线性回归模型。因此，Logistic 回归也称为对数几率回归 (Logit Regression)。因此，拟合的是对数几率。
- 交叉熵（Cross-entropy Loss）：用于度量两个概率分布（真实分布&预测分布）之间的差异性。
- Logistic 回归模型输出对应标签的后验概率：$\check{y}^{(n)} = \delta(w^T x^{(n)})$

> PS：要多多看书。结合好几本书来看，就很容易懂。网络上资源参差不齐，初学是最好的资料就是多看工具书。
>
> 书读百遍，其义自见。两个月的寒假，好好做一个书呆子。







