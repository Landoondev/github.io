# Python3 入门机器学习

> 慕课网-刘宇波老师的机器学习课程

## 1-1 什么是机器学习？

- 让机器去学习 V.S. 让机器学执行
- 最早的机器学习应用——垃圾邮件分辨
  - 传统的计算机解决思路：编写规则，定义”垃圾邮件“，让计算机执行
  - 对于很多问题，规则很难定义
  - 规则在不断变化
- 图像识别领域需要大量使学习的方法
- 黑盒子算法、白盒子算法
- 人脸识别
- 数字识别：MNIST 数据集
- 人类怎么学习？
  - 已定的样本资料 --> 学习，归纳，整理，总结 --> 知识，经验 --> 反应
- 什么是机器学习？
  - 输入大量学习资料 --> 机器学习算法 --> 模型
  - 输入样例 --> 模型 --> 输出结果
- 我们的生活中已经大量运用了机器学习
  - 判断信用卡发放是否有风险？
  - 在使用 Google 搜索时根据你输入的部分关键字，判断你真正想搜索的内容
  - 浏览商品时，最有可能购买的商品？
  - 最有可能喜欢的音乐、图书、文章？
  - 语音识别；人脸识别
  - 金融预测；医疗诊断；市场分析
- 未来将会有更多领域需要运用机器学习
  - 无人驾驶
  - 安全领域
  - 医疗领域
  - 金融领域；市场领域
  - 自然语言处理-智能翻译
  - 各种专有领域

## 1-2 课程涵盖的内容和理念

课程兼顾：

- 算法原理的学习
- 部分算法底层的编写
- scikit-learn 机器学习库的使用

## 1-3 课程所使用的主要技术栈

- 语言：Python3
- 框架：scikit-learn
- 其他：numpy、matplotlib
- IDE：Jupyter Notebook、PyCharm 

安装 ANACONDA 搞定环境。

数学基础：

- 本科高等数学、线性代数、概率论

scikit-learn 内置数据集（Toy datasets）或者通过 scikit-learn 可以直接下载的数据集。

- `load_boston`：波士顿房价
- `load_breast_cancer`：医疗领域数据集
- `load_digist`：手写数字
- `load_iris`：不同的花
- MNIST 数据集

这个课程专注于机器学习的算法学习。

- 只包含经典基础的机器学习算法，不涵盖所有机器学习算法。
- 关注于监督学习。

课程不涵盖专门领域的机器学习任务：

- 视觉领域
- 推荐系统
- 自然语言处理
- 时间序列分析
- 不包括对真实世界的数据进行预处理的过程。

- 不涵盖神经网络和深度学习

## 2-1 机器学习世界的数据？

机器学习基础概念

### 关于数据
鸢尾花数据集：[https://en.wikipedia.org/wiki/Iris_flower_data_set](<https://en.wikipedia.org/wiki/Iris_flower_data_set>)

三类鸢尾花信息

- Iris setosa 
- Iris versicalor
- Iris virginica

数据整体信息 Iris Plants Database

- 总共包含 150 个数据信息（每类 50 个）
- 每个数据给出 4 个方面的信息
  - Sepal length 萼片长度
  - Sepal width 萼片宽度
  - Petal length 花瓣长度
  - Petal width 花瓣宽度

![](./20210110/1.jpeg)

数据

- 数据整体叫做数据集（data  set）
- 每一行数据称为一个样本（sample）
- 除去最后一列，每一列表达样本的一个特征（feature），用 $X$ 表示（矩阵）。
  - 第 $i$ 个样本写作 $X^{(i)}$，第 $i$ 个样本的第 $i$ 个特征值 $X_j^{(i)}$
- 最后 一列称为标签（label），用 $y$ 表示（向量）。
  - 第 $i$ 个样本的标签写作 $y^{(i)}$

特征向量 $X^{(i)}$ 表示为列向量（$n \times 1$）。

特征空间（feature space）：

- 一个样本就是一个特征空间中的一个点。
- 分类任务本质就是特征空间切分

- 鸢尾花有 4 个特征，特征空间是 4 维的

特征可以很抽象，可以没有语义

- 图像，每一个像素点都是特征。$28 \times 28$ 的图像有 $784$ 个特征
- 如果是彩色图像特征更多

## 2-2 机器学习的主要任务

- 分类
  - 二分类：猫狗分类、垃圾邮件分类...
  - 多分类：手写数字识别（10 类）、图像识别...
    - 多分类问题可以转化为二分类任务
  - 多标签分类
- 回归
  - 房价预测，价格是一个连续数字，而不是类别

有一些算法只能解决分类问题；有一些算法只能解决回归问题。

一些情况下，回归任务可以简化成分类任务。

**监督学习**主要解决的是分类和回归问题。

## 2-3 监督学习、非监督学习，半监督学习和强化学习

监督学习：

- 给机器的训练数据拥有 “标签” 或者 “答案”。
- K 近邻
- 线性回归和多项式回归
- 逻辑回归
- SVM
- 决策树和随机森林

非监督学习：

- 对没有 “标签” 的数据进行分类——聚类分析
- 特征特取
- 特征压缩：PCA，降维
- 异常检测，离群点

半监督学习：

- 一部分数据有 “标签” 或者 “答案”，另一部分数据没有
- 更常见：各种原因产生的标签缺失
- 通常都先使用无监督学习手段对数据做处理，之后使用监督学习手段做模型的训练和预测。

强化学习

- 根据周围环境的情况，采取行动，根据采取行动的结果，学习行动方式。
- Agent、Environment、state、reward、action
- 机器人，AlphaGo

## 2-4 批量学习，在线学习，参数学习和非参数学习

- 批量学习 Batch Learning

- 在线学习 Online  Learning

### 批量学习

- 优点：简单
- 问题：如何适应环境变化？
- 解决方案：定时重新批量学习
- 缺点：每次重新批量学习，运算量巨大。在某些环境变化非常快的情况下，甚至不可能的。

###  在线学习

优点：及时反映新的环境变化

问题：新的数据带来不好的变换？

- 解决方案：需要加强对数据的监控。

其他：也适用于数据量巨大，完全无法批量学习的环境。

### 参数学习 Parametric Learning

假设房屋面积和价格的关系。

$$f(x) = ax + b$$

a 和 b 就是参数。

一旦学到了参数，就不再需要原有的数据集。

### 非参数学习 Nonparametric Learning

- 不对模型进行过多假设

- 非参数不等于没有参数！

## 2-5 和机器学习相关的哲学思考

2001 年微软的论文：如果给算法喂足够多的数据，所有的算法准确率都在提升。数据量大到一定程度时，不同的算法精度都差不多。

- 数据确实非常重要。
- 数据驱动
- 收集更多的数据
- 提高数据质量
- 提高数据的代表性
- 研究更重要的特征

算法的选择，奥卡姆的剃刀：简单的就是好的。

- 到底在机器学习领域，什么叫 “简单”？

没有免费的午餐：任意两个算法，它们的期望性能是相同的。

- 脱离具体问题，谈哪个算法好是没有意义的。

面对不确定的世界，怎么看待使用机器学习进行预测的结果？