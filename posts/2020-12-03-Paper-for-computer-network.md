# A Computational Approach to Packet Classification

![](./20201203/0.png)

è®¡ç®—æœºç½‘ç»œè¯¾ç¨‹çš„è®ºæ–‡é˜…è¯»ï¼Œè®ºæ–‡é¢˜ç›®ã€Šä¸€ç§æ•°æ®åŒ…åˆ†ç±»çš„è®¡ç®—æ–¹æ³•ã€‹

è¿™ç¯‡è®ºæ–‡æ˜¯æˆ‘é˜Ÿå‹é€‰çš„ï¼Œä¸è¿‡çœ‹èµ·æ¥è¿˜ä¸é”™ï¼Œåˆ†ç±»ï¼ˆClassificationï¼‰æ˜¯ä¸€ä¸ªéå¸¸æœ‰æ„æ€çš„é—®é¢˜ã€‚è€Œä¸”è®ºæ–‡çš„å…³é”®å­—è¿˜æœ‰ `Neural Networks`ï¼Œè¿™æ˜¯æˆ‘æœ€è¿‘åœ¨å­¦ä¹ çš„å†…å®¹ã€‚

è®ºæ–‡çš„éš¾ç‚¹åœ¨ 3.5/3.6/3.7ã€‚

## 0 æ‘˜è¦ï¼ˆABSTRACTï¼‰

å¤šå­—æ®µæ•°æ®åŒ…åˆ†ç±»ï¼ˆMulti-field packet classificationï¼‰æ˜¯ç°ä»£ç½‘ç»œçš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ã€‚

ä¸ºäº†å®ç°é«˜ååé‡ï¼ˆhigh throughputï¼‰å’Œä½å»¶è¿Ÿï¼ˆlow latencyï¼‰ï¼Œç›®å‰çš„ç®—æ³•é‡‡ç”¨çš„æ˜¯å°†è§„åˆ™æŸ¥æ‰¾æ•°æ®ç»“æ„é€‚åº”äº on-die caches ä¸­ã€‚

>  state-of-the-art algorithms strive to fit the rule lookup data structures into on-die caches.
>
> PSï¼šon-die caches çš„æ„æ€æ˜¯ CPU èŠ¯ç‰‡å†…é›†æˆç¼“å­˜ã€‚

ç›®å‰çš„ç®—æ³•çš„ä¸€ä¸ªé™åˆ¶æ˜¯æ— æ³•éšç€è§„åˆ™æ•°é‡çš„å¢åŠ è€Œæ‰©å±•ã€‚

è®ºæ–‡ä¸­æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼š*NuevoMatch*ï¼Œå®ƒæ”¹è¿›äº†ç°æœ‰æ–¹æ³•çš„å†…å­˜æ‰©å±•ã€‚

- ä½¿ç”¨äº†ä¸€ç§æ–°çš„æ•°æ®ç»“æ„ï¼ˆRange Query Recursive Model Indexï¼‰ï¼Œä½¿å¾— *NuevoMatch* èƒ½å¤Ÿç”¨æ¨¡å‹æ¨ç†è®¡ç®—å–ä»£å¤§éƒ¨åˆ†å¯¹ä¸»å†…å­˜çš„è®¿é—®ã€‚
- RQ-RMI çš„ä½¿ç”¨å…è®¸å°†è§„åˆ™å‹ç¼©æˆé€‚åˆç¡¬ä»¶ç¼“å­˜çš„æ¨¡å‹æƒé‡ã€‚

- è¯¦ç»†ä»‹ç»äº†ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒç®—æ³•ï¼Œä¿è¯äº†åŸºäº RQ-RMI çš„åˆ†ç±»çš„æ­£ç¡®æ€§ã€‚
- åˆ©ç”¨äº†ç°ä»£ CPU å¯¹å¿«é€Ÿç¥ç»ç½‘ç»œå¤„ç†çš„æ—¥ç›Šæ”¯æŒï¼Œå¦‚å®½å‘é‡æŒ‡ä»¤ï¼ˆwide vector instructionsï¼‰ï¼Œå®ç°äº†åçº³ç§’å•æ¬¡æŸ¥è¯¢çš„é€Ÿåº¦ã€‚
- *NuevoMatch* ä¸ CutSplitã€NeuroCuts å’Œ TupleMerge ç®—æ³•ç›¸æ¯”ï¼Œå‡ ä½•å¹³å‡å‹ç¼©ç³»æ•°åˆ†åˆ«ä¸º 4.9Ã—ã€8Ã— å’Œ 82Ã—ï¼Œååé‡çš„å¹³å‡æ€§èƒ½æé«˜äº† 2.4Ã—ã€2.6Ã— å’Œ 1.6Ã— ã€‚

## 1 ä»‹ç»ï¼ˆINTRODUCTIONï¼‰

*NuevoMatch* æºç ï¼šhttps://github.com/acsl-technion/nuevomatch

æ•°æ®åŒ…åˆ†ç±»æ˜¯æ•°æ®åŒ…äº¤æ¢ç½‘ç»œçš„åŸºçŸ³ã€‚æ•°æ®åŒ…åˆ†ç±»çš„æ„æ€æ˜¯ï¼Œç½‘ç»œå‡½æ•°ï¼ˆNetwork functionsï¼‰å¦‚äº¤æ¢æœºï¼Œä½¿ç”¨ä¸€å¥—è§„åˆ™å¯¹æ¥æ”¶åˆ°çš„æ¯ä¸ªæ•°æ®åŒ…é‡‡å–æŸäº›ç­–ç•¥ã€‚

æ•°æ®åŒ…åˆ†ç±»ç®—æ³•ç›®å‰çš„ç ”ç©¶ä¸»è¦æœ‰ä¸¤ç±»ï¼šä¸€ç±»æ˜¯ä¾èµ–äºä¸‰æ€å†…å®¹å¯»å€å­˜å‚¨å™¨ï¼ˆTernary Content Addressable Memory, TCAMï¼‰ç¡¬ä»¶çš„ç®—æ³•ï¼›å¦ä¸€ç±»æ˜¯åœ¨è½¯ä»¶ä¸­å®ç°çš„ç®—æ³•ã€‚è¿™ç¯‡è®ºæ–‡æ‰€ä¸“æ³¨çš„æ˜¯çº¯è½¯ä»¶çš„ç®—æ³•ã€‚

ä¸»æµè½¯ä»¶ç®—æ³•å¯ä»¥åˆ†ä¸ºä¸¤å¤§ç±»ï¼šåŸºäºå†³ç­–æ ‘ï¼ˆdecision-tree basedï¼‰å’ŒåŸºäºå“ˆå¸Œï¼ˆhash-basedï¼‰ã€‚å…¶ä»–çš„æ•°æ®åŒ…åˆ†ç±»æ–¹è¦ä¹ˆéœ€è¦å¤ªå¤šå†…å­˜ï¼Œè¦ä¹ˆé€Ÿåº¦å¤ªæ…¢ã€‚

ç°ä»£ CPU çš„ on-die cache èƒ½å¤Ÿæå‡åˆ†ç±»çš„æ€§èƒ½ã€‚ä½†æ˜¯éšç€è§„åˆ™æ•°æ®çš„å¢åŠ ï¼Œç¼“å­˜çš„ç»´æŠ¤å˜å¾—æ›´åŠ å›°éš¾ã€‚

CutSplit å’Œ NeuroCuts ç­‰æ–¹æ³•è¯•å›¾å‡å°‘è§„åˆ™å¤åˆ¶ä»¥å®ç°æ›´å¥½çš„æ‰©å±•ï¼Œä½†æ˜¯ç”±äºç°ä»£æ•°æ®ä¸­å¿ƒçš„è§„åˆ™é›†å¯èƒ½è¾¾åˆ°æ•°åä¸‡æ¡ï¼Œæ‹“å±•ä¹Ÿå­˜åœ¨ç€é—®é¢˜ã€‚

åŸºäºå“ˆå¸Œçš„æŠ€æœ¯ä¹Ÿå­˜åœ¨æ‰©å±•æ€§å·®çš„é—®é¢˜ã€‚

åœ¨æ­¤èƒŒæ™¯ä¹‹ä¸‹ï¼Œæœ¬ç¯‡è®ºæ–‡ï¼š

- æå‡ºäº†ä¸€ç§æ–°å‹çš„æ•°æ®åŒ…åˆ†ç±»æ–¹æ³• *NuevoMatch*ã€‚å®ƒèƒ½æå¤§åœ°å‹ç¼©è§„åˆ™é›†ç´¢å¼•ï¼Œå³ä½¿å¯¹äº 500K çš„å¤§è§„åˆ™é›†ï¼Œä¹Ÿèƒ½å°†å…¶å®Œå…¨æ”¾å…¥ CPU ç¼“å­˜çš„ä¸Šå±‚ï¼ˆL1/L2ï¼‰ã€‚
- å¼•å…¥äº†ä¸€ç§æ–°å‹çš„ *Range Query Recursive Model Index*(RQ-RMI) æ¨¡å‹ï¼Œå¹¶è®­ç»ƒå®ƒæ¥å­¦ä¹ è§„åˆ™çš„åŒ¹é…é›†ï¼Œå°†è§„åˆ™åŒ¹é…å˜æˆç¥ç»ç½‘ç»œæ¨ç†ã€‚
- ä¸ç°æœ‰çš„æ–¹æ³•å¯¹æ¯”ï¼ˆCutSplitã€NeuroCutsã€TupleMergï¼‰å¹³å‡å‡å°‘äº† 4.9Ã—ã€8Ã— å’Œ 82Ã— çš„å†…å­˜å ç”¨ã€‚

***NuevoMatch* æ˜¯ç¬¬ä¸€ä¸ªä½¿ç”¨è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæ¨¡å‹æ¥è¿›è¡Œæ•°æ®åŒ…åˆ†ç±»çš„ã€‚** 

RQ-RMI æ¯”å†³ç­–æ ‘æˆ–å“ˆå¸Œè¡¨æ›´èŠ‚çœç©ºé—´ï¼Œå°†æ‰©å±•æ€§æé«˜äº†ä¸€ä¸ªæ•°é‡çº§ã€‚

*NuevoMatch* å°†æ•°æ®åŒ…åˆ†ç±»ä»»åŠ¡ä»å†…å­˜çº¦æŸè½¬å˜ä¸ºè®¡ç®—çº¦æŸï¼ˆmemory- to compute-bound. ï¼‰ã€‚éšç€ç¥ç»ç½‘ç»œæ¨ç†ç¡¬ä»¶åŠ é€Ÿçš„å¿«é€Ÿå‘å±•ï¼Œè¿™ç§è®¾è®¡åœ¨æœªæ¥å¯èƒ½ä¼šæœ‰å¾ˆå¥½çš„æ‰©å±•ã€‚

*NuevoMatch* å»ºç«‹åœ¨ ***learned indexes*** ä¹‹ä¸Šï¼ˆ*Kraska et al., 2018. The Case for Learned Index Structures.*ï¼‰ã€‚NuevoMatch å°†é€’å½’æ¨¡å‹ç´¢å¼•ï¼ˆRMIï¼‰åº”ç”¨äºé”®-å€¼å¯¹ï¼ˆkey-value pairsï¼‰çš„ç´¢å¼•ã€‚å€¼å­˜å‚¨åœ¨æ•°ç»„ä¸­ï¼ŒRMI è¢«è®­ç»ƒæˆå­¦ä¹ æ•°ç»„ä¸­é”®å’Œå…¶å€¼çš„ç´¢å¼•ä¹‹é—´çš„æ˜ å°„å‡½æ•°ï¼Œæ¨¡å‹ç”¨äºé¢„æµ‹ç»™å®šçš„é”®çš„ç´¢å¼•ï¼Œé€šè¿‡å¾—åˆ°çš„ç´¢å¼•è·å–åˆ° valueã€‚

RMI ä¸èƒ½ç›´æ¥é€‚ç”¨äºæ•°æ®åŒ…åˆ†ç±»ï¼ŒåŸå› å¦‚ä¸‹ï¼š

- ä¸€ä¸ªé”®ï¼ˆåŒ…å­—æ®µï¼‰å¯èƒ½æ²¡æœ‰ä¸€ä¸ªç²¾ç¡®çš„åŒ¹é…å€¼ï¼Œè€Œæ˜¯åŒ¹é…ä¸€ä¸ªè§„åˆ™èŒƒå›´ï¼Œè€ŒRMIåªèƒ½å­¦ä¹ ç²¾ç¡®çš„é”®-ç´¢å¼•å¯¹ã€‚
- ä¸€ä¸ªé”®å¯èƒ½åŒ¹é…å¤šä¸ªè§„åˆ™ï¼Œä¼˜å…ˆçº§æœ€é«˜çš„ä¸€ä¸ªä½œä¸ºè¾“å‡ºï¼Œè€Œ RMI åªæ£€ç´¢æ¯ä¸ªé”®çš„å•ä¸€ç´¢å¼•ã€‚

NuevoMatch æˆåŠŸè§£å†³äº†å¦‚ä¸‹éš¾é¢˜ï¼š

- RQ-RMIï¼šå°†å¯†é’¥ä¸èŒƒå›´è¿›è¡ŒåŒ¹é…ï¼Œå¹¶é‡‡ç”¨é«˜æ•ˆçš„è®­ç»ƒç®—æ³•ï¼Œä¸éœ€è¦ç©·å°½å¯†é’¥æšä¸¾æ¥å­¦ä¹ èŒƒå›´ã€‚æ¨¡å‹å¯ä»¥åœ¨ 35 KB å†…å­˜å‚¨ 500K ClassBench è§„åˆ™çš„ç´¢å¼•ã€‚
- Multi-field packet classificationï¼šåˆ†ç±»æµç¨‹å¦‚ Figure 1 æ‰€ç¤ºã€‚NuevoMatch å¯ä»¥çœ‹ä½œæ˜¯ç°æœ‰æ•°æ®åŒ…åˆ†ç±»æŠ€æœ¯çš„è¡¥å……ã€‚

![](./20201203/1.png)

---

è¿™ç¯‡è®ºæ–‡çš„è´¡çŒ®æ€»ç»“å¦‚ä¸‹ï¼š

- æå‡ºäº†ä¸€ç§æ–°å‹çš„ RQ-RMI æ¨¡å‹å’Œä¸€ç§å­¦ä¹ æ•°æ®åŒ…åˆ†ç±»è§„åˆ™çš„è®­ç»ƒæŠ€æœ¯ã€‚

- å±•ç¤ºäº† RQ-RMI åœ¨ multi-field packet åˆ†ç±»çš„åº”ç”¨ã€‚
- NuevoMatch åœ¨å†…å­˜å ç”¨ã€å»¶è¿Ÿå’Œååé‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ï¼ŒNuevoMatch å°†å¤šè¾¾ 500K çš„è§„åˆ™å‹ç¼©åˆ°é€‚åˆç°ä»£å¤„ç†å™¨çš„å°å‹ç¼“å­˜ä¸­ã€‚

## 2 èƒŒæ™¯ï¼ˆBACKGROUNDï¼‰

èƒŒæ™¯éƒ¨åˆ†ä¸»è¦ä»‹ç»å¯¹äºæ•°æ®åŒ…åˆ†ç±»é—®é¢˜ç°æœ‰çš„è§£å†³æ–¹æ¡ˆã€‚

### æ•°æ®åŒ…åˆ†ç±»

æ•°æ®åŒ…åˆ†ç±»æ˜¯åœ¨ä¸€ç»„è§„åˆ™ä¸­æ‰¾åˆ°ä¸€ä¸ªè¾“å…¥æ•°æ®åŒ…æ‰€æ»¡è¶³çš„å•ä¸€è§„åˆ™çš„è¿‡ç¨‹ï¼Œä¸€ä¸ªæ•°æ®åŒ…å¯èƒ½ä¼šåŒ¹é…å¤šä¸ªè§„åˆ™ï¼Œä½†åªæœ‰ä¼˜å…ˆçº§æœ€é«˜çš„é‚£ä¸ªè§„åˆ™æ‰ä¼šè¢«é€‰ä¸­ã€‚

Figure 2 ä¸¾ä¾‹äº†ä¸€ä¸ªå…·æœ‰ä¸¤ä¸ªå­—æ®µå’Œäº”ä¸ªé‡å åŒ¹é…è§„åˆ™çš„åˆ†ç±»å™¨ã€‚ä¸€ä¸ªä¼ å…¥çš„æ•°æ®åŒ…åŒ¹é…äº†ä¸¤æ¡è§„åˆ™ï¼ˆR3ï¼ŒR4ï¼‰ï¼Œä½† R3 è¢«ä½¿ç”¨ï¼Œå› ä¸ºå®ƒçš„ä¼˜å…ˆçº§æ›´é«˜ã€‚

![](./20201203/2.png)

### åˆ†ç±»ç®—æ³•

#### 1. å†³ç­–æ ‘ç®—æ³•

ä¸ºäº†åŒ¹é…ä¸€ä¸ªè§„åˆ™ï¼Œæ ‘å½¢éå†ä¸ºç»™å®šæ•°æ®åŒ…æ‰¾åˆ°æœ€å°çš„å­é›†ã€‚

è§„åˆ™å¤åˆ¶é—®é¢˜å½±å“äº†å¤§è§„åˆ™é›†çš„æ€§èƒ½ã€‚ä¾‹å¦‚å½“ä¸€æ¡è§„åˆ™è·¨è¶Šå‡ ä¸ªå­ç©ºé—´æ—¶ï¼Œæ ‘çš„å†…å­˜å ç”¨é‡ä¼šæ€¥å‰§å¢åŠ ï¼ˆHiCutsã€HyperCuts å­˜åœ¨æ­¤é—®é¢˜ï¼‰ã€‚

EffiCuts å’Œ CutSplit å°†è§„åˆ™é›†åˆ†å‰²æˆå…·æœ‰ç›¸ä¼¼å±æ€§çš„è§„åˆ™ç»„ï¼Œå¹¶ä¸ºæ¯ä¸ªè§„åˆ™ç»„ç”Ÿæˆç‹¬ç«‹çš„å†³ç­–æ ‘ã€‚

NeuroCuts æ˜¯è¯¥é¢†åŸŸæœ€æ–°çš„å·¥ä½œï¼Œå®ƒä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥ä¼˜åŒ–å†³ç­–æ ‘å‚æ•°ï¼Œé€šè¿‡æœ‰æ•ˆæ¢ç´¢å¤§æ ‘é…ç½®ç©ºé—´æ¥å‡å°‘å…¶å†…å­˜å ç”¨ï¼Œæˆ–éå†è¿‡ç¨‹ä¸­çš„å†…å­˜è®¿é—®æ¬¡æ•°ã€‚

#### 2. Hash ç®—æ³•

Tuple Space Search å’Œ TupleMerge æ ¹æ®æ¯ä¸ªå­—æ®µçš„å‰ç¼€ä½æ•°å°†è§„åˆ™é›†åˆ’åˆ†ä¸ºå­é›†ã€‚ç”±äºä¸€ä¸ªå­é›†çš„æ‰€æœ‰è§„åˆ™éƒ½å…·æœ‰ç›¸åŒçš„å‰ç¼€ä½æ•°ï¼Œå®ƒä»¬å¯ä»¥ä½œä¸ºå“ˆå¸Œè¡¨ä¸­çš„é”®ã€‚

åˆ†ç±»æ—¶æå–ä¼ å…¥æ•°æ®åŒ…çš„æ‰€æœ‰å­—æ®µä¸­çš„å‰ç¼€ä½ï¼Œç„¶åè¿›è¡Œ Hash æœç´¢ã€‚

#### å­˜åœ¨çš„ç¼ºç‚¹

å†³ç­–æ ‘ç®—æ³•å’Œ Hash ç®—æ³•åœ¨å¤§è§„æ¨¡çš„è§„åˆ™é›†ä¸Šçš„æ€§èƒ½å¾ˆå¼±ï¼ˆPoor performance with large rule-setsï¼‰ã€‚åˆ†ç±»æ€§èƒ½å¹¶ä¸èƒ½å¾ˆå¥½åœ°éšç€è§„åˆ™æ•°é‡çš„å¢åŠ è€Œæ‰©å±•ã€‚

NuevoMatch æä¾›æ›´æœ‰æ•ˆçš„è§„åˆ™ç´¢å¼•ç©ºé—´è¡¨ç¤ºï¼Œä»¥æ‰©å±•åˆ°å¤§å‹è§„åˆ™é›†ã€‚

## 3 NUEVOMATCH ç»“æ„

### 3.1 Recursive Model Indexï¼ˆRMIï¼‰

Kraskaç­‰äººæå‡ºä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹æ¥å­˜å‚¨é”®å€¼å¯¹ï¼Œå°†å€¼å­˜å‚¨åœ¨å€¼æ•°ç»„ä¸­ï¼Œå¹¶ä½¿ç”¨é€’å½’æ¨¡å‹ç´¢å¼•ï¼ˆRMIï¼‰æ¥æ£€ç´¢ç»™å®šé”®çš„å€¼ã€‚

RMI ä½¿ç”¨å­¦ä¹ äº†åº•å±‚é”®-ç´¢å¼•æ˜ å°„å‡½æ•°çš„æ¨¡å‹æ¥é¢„æµ‹å€¼æ•°ç»„ä¸­ç›¸åº”å€¼çš„ç´¢å¼•ã€‚

$$y = h(x)$$

RMI è®­ç»ƒå­¦ä¹  $h(x)$ ã€‚æ‰€å¾—çš„å­¦ä¹ ç´¢å¼•æ¨¡å‹ $h(x)$ åˆ†ä¸¤ä¸ªé˜¶æ®µè¿›è¡ŒæŸ¥æ‰¾ï¼š

- é¦–å…ˆè®¡ç®—å‡ºé¢„æµ‹ç´¢å¼• $y= h(key)$ 
- ç„¶ååœ¨æ•°ç»„ä¸­ï¼Œåœ¨é¢„æµ‹ç´¢å¼•çš„é™„è¿‘ $\epsilon$ è¿›è¡ŒäºŒæ¬¡æŸ¥æ‰¾ï¼Œå…¶ä¸­ $\epsilon$ ä¸ºæ¨¡å‹çš„æœ€å¤§ç´¢å¼•é¢„æµ‹è¯¯å·®ï¼Œå³ $\left\vert \check{h}(key)-h(key) \right\vert \leq \epsilon$ã€‚

RMI Model ç»“æ„å¦‚ä¸‹å›¾ï¼š

![](./20201203/3.png)

è®­ç»ƒæ—¶ä¸€ä¸ªé˜¶æ®µä¸€ä¸ªé˜¶æ®µçš„è¿›è¡Œçš„ï¼ˆTraining is performed stage by stage.ï¼‰ã€‚

- First stage.
- Internal stage.
- Last stage.

è¯„ä¼°æ—¶ï¼Œç»™å®šä¸€ä¸ª keyï¼Œä» $m_{0,0}$ å¼€å§‹ï¼Œä¸€ä¸ªé˜¶æ®µä¸€ä¸ªé˜¶æ®µåœ°è¿­ä»£è¯„ä¼°æ¯ä¸ª submodelã€‚æœ€åé˜¶æ®µçš„ submodel é¢„æµ‹æ•°ç»„ä¸­çš„ç´¢å¼• $\check{i}$ï¼ˆThe last selected submodel predicts the index in the value array. ï¼‰ã€‚äºŒæ¬¡æœç´¢çš„èŒƒå›´ä¸º $[\check{i} - \epsilon, \check{i} + \epsilon]$ã€‚

### 3.2 RMI é™åˆ¶

- ä¸æ”¯æŒèŒƒå›´åŒ¹é…ï¼šRMI åªå…è®¸ç²¾ç¡®çš„çš„åŒ¹é…ï¼ˆ1 å¯¹ 1ï¼‰ï¼Œè€Œæ•°æ®åŒ…åˆ†ç±»åˆ™éœ€è¦æ£€ç´¢é€šé…ç¬¦å®šä¹‰çš„åŒ¹é…èŒƒå›´çš„è§„åˆ™ã€‚
- å¤šç»´ç´¢å¼•é€Ÿåº¦æ…¢ï¼šæœ‰é€šé…ç¬¦çš„æƒ…å†µä¸‹ä¼šç”ŸæˆæŒ‡æ•°çº§æ•°é‡çš„è§„åˆ™ï¼Œéœ€è¦çš„ç¼“å­˜ç©ºé—´å¤ªå¤§ã€‚

### 3.3 RQ-RMI

RQ-RMIï¼šè§£å†³ RMI No support for range matching é—®é¢˜ã€‚

> *if a submodel is a piece-wise linear functionï¼ˆåˆ†æ®µçº¿æ€§å‡½æ•°ï¼‰, the worst-case error bound Îµ can be computed analytically.* thereby enabling efficient learning of ranges.

å¦‚ä¸‹ Figure 4ï¼Œè¾“å…¥ $t_i$ ç§°ä¸º *transition inputs*ï¼Œè¾“å‡ºæ˜¯å¤§å°ä¸º 4 çš„æ•°ç»„ä¸­çš„ç´¢å¼•ï¼ŒèŒƒå›´ï¼š`[0, 4)`ã€‚ç»™å®šæ¨¡å‹çš„è¾“å…¥èŒƒå›´ï¼Œè¦è®¡ç®—æ¨¡å‹å¯¹è¯¥èŒƒå›´å†…ä»»ä½•é”®çš„æœ€å¤§é¢„æµ‹è¯¯å·®ï¼Œåªéœ€è¯„ä¼°è½åœ¨è¯¥èŒƒå›´å†…çš„ Transition inputs é¢„æµ‹è¯¯å·®å³å¯ã€‚

![](./20201203/4.png)

piece-wise linear function. åˆ†æ®µçº¿æ€§å‡½æ•°ã€‚

### 3.4 ä½¿ç”¨ç¥ç»ç½‘ç»œä½œä¸º submodel

ä½¿ç”¨ 3 å±‚çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œæ¿€æ´»å‡½æ•°ä¸º ReLUã€‚

*RQ-RMI submodel* å®šä¹‰ï¼š

$$N_{i, j}(x) = A(x \cdot w_1 + b_1) \times w_2 + b$$

$x$ ä¸ºæ ‡é‡è¾“å…¥ï¼Œ$w_1, b_1$ çš„ç¬¬ä¸€ä¸ªéšè—å±‚æƒé‡å’Œåç½®ï¼Œ$w_2, b_2$ ä¸ºç¬¬äºŒå±‚çš„æƒé‡å’Œåç½®ï¼Œ$A$ ä¸º ReLU å‡½æ•°ã€‚$N_{i, j}(x)$ æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚

æ¨¡å‹çš„è¾“å‡ºå®šä¹‰ä¸º: $M_{i, j}(x) = H(N_{i, j}(x))$ã€‚H å‡½æ•°å°†è¾“å‡ºçš„èŒƒå›´é™åœ¨åŒºé—´ $[0, 1)$ã€‚

$M_{i, j}(x)$ æ˜¯ä¸€ä¸ªåˆ†æ®µçº¿æ€§å‡½æ•°ã€‚

### 3.5 ğŸ”´ RQ-RMI çš„è®­ç»ƒ

- ***Overview.***

RQ-RMI çš„è®­ç»ƒæ–¹å¼ä¸ RMI ç±»ä¼¼ï¼Œä¹Ÿæ˜¯æŒ‰é˜¶æ®µè¿›è¡Œçš„ã€‚ä¸€ä¸ªé˜¶æ®µçš„è®­ç»ƒè¿‡ç¨‹å¦‚ Figure 5 æ‰€ç¤ºã€‚

![](./20201203/5.png)

- ***Computing transition inputs.***

![](./20201203/4.png)

ç»™å®šä¸€ä¸ªè®­ç»ƒå¥½çš„ submodel $m$ï¼Œå¯ä»¥æ‰¾åˆ°å®ƒçš„æ‰€æœ‰çº¿æ€§åŒºåŸŸå’Œåˆ’åˆ†è¿™äº›åŒºåŸŸçš„è¾“å…¥ã€‚è¿™äº›è¾“å…¥ç§°ä¸º trigger inputs $g_l$ã€‚å¯¹äºèŒƒå›´ $[g_lï¼Œg_{l+1}]$ ä¸­çš„æ‰€æœ‰è¾“å…¥ï¼Œæ„é€ çš„æ¨¡å‹å‡½æ•° $M(x)$ æ˜¯çº¿æ€§çš„ã€‚

å®šä¹‰ä¸€ä¸ª step-wise function: $Q = \left\lfloor M(X) \cdot W \right\rfloor / W$ã€‚

W æ˜¯é‡åŒ–è¾“å‡ºåŸŸçš„å¤§å°ï¼ˆå›¾4ï¼‰ã€‚å¯¹äºæ¯ä¸ªè¾“å…¥èŒƒå›´ $[g_lï¼Œg_{l+1}]$ï¼Œ transition inputs $t_l \in T$ çš„é›†åˆæ˜¯ M(x) å’Œ Q ç›¸äº¤çš„é‚£éƒ¨åˆ†ã€‚

- ***Computing the responsibilities of submodels in the following stage.*** 

å­æ¨¡å‹ï¼š`submodel`ï¼Œè´£ä»»ï¼š`responsibility`

è®¡ç®—ä¸‹ä¸€é˜¶æ®µå„å­æ¨¡å‹çš„è´£ä»»ã€‚

ç»™å®šä¸€ä¸ªå†…éƒ¨é˜¶æ®µ $i$ ä¸­çš„è®­ç»ƒå¥½çš„å­æ¨¡å‹ $m_{i,j}$ï¼Œå®ƒå°†ä¸€ä¸ª *key* æ˜ å°„åˆ°ä¸€ä¸ªå­æ¨¡å‹ $m_{i+1,k}$ï¼Œ$k < W_{i+1}$ï¼Œå¦‚æœ $\left\lfloor M_{i, j}(key) \cdot W_{i+1} \right\rfloor = k$ã€‚

ç¬¬ $i$ é˜¶æ®µçš„è®­ç»ƒè¿‡çš„å­æ¨¡å‹å®šä¹‰äº†ç¬¬ $i+1$ é˜¶æ®µæœªè®­ç»ƒè¿‡çš„å­æ¨¡å‹çš„è´£ä»»ã€‚

å­æ¨¡å‹çš„è´£ä»»ï¼ˆresponsibility of a submodelï¼‰å†³å®šäº†ç”¨äºè®­ç»ƒå­æ¨¡å‹çš„è¾“å…¥å­é›†ã€‚ä½¿ç”¨ $m_{i,j}$ çš„ transition inputs æ¥è®¡ç®— $R_{i+1,k}$ã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œå‡è®¾ $R_{i,j}$ æ˜¯è¿ç»­çš„ï¼Œå¹¶ä¸” $m_{i, j}$ æ˜¯é˜¶æ®µ $i$ çš„å”¯ä¸€å­æ¨¡å‹ã€‚

é€šè¿‡è®¡ç®— $R_{i+1,k}$ ï¼Œè§‚å¯Ÿåˆ°å®ƒæ˜¯ç”±æ˜ å°„åˆ°å­æ¨¡å‹ $m_{i+1,k}$ çš„åŒºåŸŸ $(t_l ï¼Œt_{l+1})$ ä¸­çš„æ‰€æœ‰è¾“å…¥ç»„æˆã€‚å…¶ä¸­ $t_l \in Ti,j$ æ˜¯ $m_{i,j}$ çš„ transition inputsã€‚æ ¹æ®æ„é€ ï¼Œä¸¤ä¸ªç›¸é‚» transition points ä¹‹é—´åŒºåŸŸçš„è¾“å…¥æ˜ å°„åˆ°åŒä¸€ä¸ªè¾“å‡ºã€‚ç„¶åï¼Œåªéœ€è®¡ç®— $m_{i,j}$ çš„ transition points çš„è¾“å‡ºï¼Œå¹¶é€‰æ‹©å„è‡ªçš„è¾“å…¥èŒƒå›´ï¼Œæ˜ å°„åˆ° $m_{i+1,k}$ã€‚

- ***Training a submodel with ranges using sampling.*** 

ä¸“æ³¨äºå¯¹è¾“å…¥èŒƒå›´çš„è®­ç»ƒã€‚ä¸€ä¸ªèŒƒå›´å¯ä»¥è¡¨ç¤ºä¸ºå±äºè¯¥èŒƒå›´çš„æ‰€æœ‰é”®ï¼ˆkeyï¼‰ï¼Œéƒ½ä¸å„è‡ªè§„åˆ™çš„ç›¸åŒç´¢å¼•ç›¸å…³è”ã€‚

ä¾‹å¦‚ï¼Œ10.1.1.0-10.1.1.255 åŒ…æ‹¬ 256 ä¸ªé”®ã€‚æ¥ä¸‹æ¥çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä½¿ç»™å®šèŒƒå›´å†…çš„ä¸€ä¸ªé”®ï¼Œæ¨¡å‹èƒ½é¢„æµ‹å‡ºæ­£ç¡®çš„ç´¢å¼•ã€‚

ä½¿ç”¨é‡‡æ ·æ¥è®­ç»ƒä¸€ä¸ªæœ‰èŒƒå›´çš„å­æ¨¡å‹ã€‚

é€šè¿‡å¯¹å­æ¨¡å‹çš„è´£ä»»è¿›è¡Œç»Ÿä¸€æŠ½æ ·æ¥ç”Ÿæˆè®­ç»ƒ key-index å¯¹ã€‚ä»ä½é‡‡æ ·é¢‘ç‡å¼€å§‹ï¼Œå¦‚æœæœ‰ä¸€ä¸ªè¾“å…¥è§„åˆ™èŒƒå›´ä¸é‡‡æ ·çš„é”®ç›¸åŒ¹é…ï¼Œé‚£ä¹ˆä¸€ä¸ªæ ·æœ¬å°±ä¼šè¢«åŒ…å«åœ¨è®­ç»ƒé›†ä¸­ã€‚æ¯ä¸ªè¾“å…¥èŒƒå›´çš„æ ·æœ¬æ•°é‡ä¸å…¶åœ¨å­æ¨¡å‹çš„è´£ä»»ä¸­çš„ç›¸å¯¹å¤§å°æˆæ­£æ¯”ã€‚

- ***Submodel training.*** 

ä½¿ç”¨ç›‘ç£å­¦ä¹ å’Œ Adam ä¼˜åŒ–å™¨å¯¹ç”Ÿæˆçš„æ•°æ®é›†è¿›è¡Œå­æ¨¡å‹è®­ç»ƒï¼ŒæŸå¤±å‡½æ•°ä¸ºå‡æ–¹è¯¯å·®ï¼ˆmean squared error loss function.ï¼‰ã€‚

- ***Computing error bounds.***

ç»™å®šä¸€ä¸ªä¸Šä¸€é˜¶æ®µè®­ç»ƒå¥½çš„å­æ¨¡å‹ï¼Œé€šè¿‡å¯¹å­æ¨¡å‹çš„ transition inputs è¿›è¡Œè¯„ä¼°ï¼Œè®¡ç®—å…¶è´£ä»»ä¸­æ‰€æœ‰è¾“å…¥çš„é¢„æµ‹è¯¯å·®è¾¹ç•Œã€‚

> compute the prediction error bound for all inputs in its responsibility by evaluating the submodel on its transition inputs. 

å¦‚æœè¯¯å·®è¿‡å¤§ï¼Œå¯ä»¥å°†æ ·æœ¬æ•°é‡å¢åŠ ä¸€å€ï¼Œé‡æ–°ç”Ÿæˆ key-index å¯¹ï¼Œå¹¶é‡æ–°è®­ç»ƒå­æ¨¡å‹ã€‚

å¦‚æœè®­ç»ƒæ²¡æœ‰æ”¶æ•›ï¼Œå¯ä»¥é€‚å½“å¢åŠ ç›®æ ‡è¯¯å·®è¾¹ç•Œ $\epsilon$ çš„å€¼ã€‚è¾ƒå¤§çš„äºŒæ¬¡æœç´¢çš„æœç´¢è·ç¦»ï¼Œä¼šå¯¼è‡´ç³»ç»Ÿæ€§èƒ½é™ä½ã€‚

### 3.6ğŸ”´ Handling multi-dimensional queries with
NuevoMatch é€šè¿‡ç»“åˆä¸¤ä¸ªç®€å•çš„æ€æƒ³æ¥æ”¯æŒå¤šç»´åº¦ï¼š

- 1. partitioning the rule-set into disjoint independent sets (iSets).
- 2. performing multi-field validation of each rule. In the following.

**Partitioning**

æ¯ä¸ª iSet åŒ…å«çš„è§„åˆ™åœ¨ä¸€ä¸ªç‰¹å®šçš„ç»´åº¦ä¸Šä¸é‡å ã€‚

å¦‚æœè§„åˆ™åœ¨è‡³å°‘ä¸€ä¸ªç»´åº¦ä¸Šä¸é‡å ï¼Œä¸€ä¸ª iSet å¯ä»¥è¦†ç›–æ‰€æœ‰çš„è§„åˆ™ï¼Œè€ŒåŒä¸€ç»´åº¦çš„è®¸å¤šé‡å èŒƒå›´å¯èƒ½éœ€è¦å¤šä¸ª iSetã€‚å›¾ 6 æ˜¾ç¤ºäº†å›¾ 2 ä¸­è§„åˆ™çš„ iSetsã€‚

![](./20201203/6-1.png)

æ¯ä¸ª iSet ç”±ä¸€ä¸ª RQ-RMI ç´¢å¼•ã€‚å› æ­¤ï¼Œä¸ºäº†æ‰¾åˆ°ä¸€ä¸ªæœ‰å¤šä¸ªå­—æ®µçš„æŸ¥è¯¢çš„åŒ¹é…ï¼Œéœ€è¦æŸ¥è¯¢æ‰€æœ‰çš„ RQ-RMIï¼ˆå¹¶è¡Œï¼‰ï¼Œæ¯ä¸ª RQ-RMI éƒ½åœ¨å®ƒæ‰€è®­ç»ƒçš„å­—æ®µä¸Šã€‚ç„¶åï¼Œé€‰æ‹©ä¼˜å…ˆçº§æœ€é«˜çš„ç»“æœä½œä¸ºè¾“å‡ºã€‚

æ¯ä¸ª iSet éƒ½ä¼šå¢åŠ  NuevoMatch çš„æ€»å†…å­˜æ¶ˆè€—å’Œè®¡ç®—éœ€æ±‚ã€‚å› æ­¤ï¼Œå¼•å…¥äº†ä¸€ç§å¯å‘å¼æ–¹æ³•ï¼ŒåŠ›æ±‚æ‰¾åˆ°è¦†ç›–è§„åˆ™é›†æœ€å¤§éƒ¨åˆ†çš„æœ€å°æ•°é‡çš„ iSetsã€‚

> Each iSet is indexed by one RQ-RMI. Thus, to find the match to a query with multiple fields, we query all RQ-RMIs (in parallel), each over the field on which it was trained. Then, the highest priority result is selected as the output. 
>
> Each iSet adds to the total memory consumption and compu- tational requirements of NuevoMatch. Therefore, we introduce a heuristic that strives to find the smallest number of iSets that cover the largest part of the rule-set (Â§3.6.1). 

**Multi-field validation**

ç”±äº RQ-RMI åœ¨å•ä¸ªå­—æ®µä¸Šå»ºç«‹è§„åˆ™ç´¢å¼•ï¼Œå®ƒå¯èƒ½æ£€ç´¢åˆ°ä¸å…¶ä»–å­—æ®µä¸åŒ¹é…çš„è§„åˆ™ã€‚å› æ­¤ï¼ŒRQ-RMI è¿”å›çš„æ¯æ¡è§„åˆ™éƒ½ä¼šåœ¨æ‰€æœ‰å­—æ®µä¸Šè¿›è¡ŒéªŒè¯ã€‚è¿™ä½¿å¾— NuevoMatch èƒ½å¤Ÿé¿å…å¯¹æ‰€æœ‰ç»´åº¦è¿›è¡Œç´¢å¼•ï¼Œä½†åˆèƒ½è·å¾—æ­£ç¡®çš„ç»“æœã€‚

### 3.7ğŸ”´ Remainder set å’Œ external classifiers

![](./20201203/1-1.png)

ç°å®ä¸–ç•Œçš„è§„åˆ™é›†å¯èƒ½éœ€è¦è®¸å¤š iSets æ¥å®ç°å…¨é¢è¦†ç›–ã€‚å¯¹äºé‚£äº›æ¯”è¾ƒå°çš„ iSetsï¼Œä½¿ç”¨å•ç‹¬çš„ RQ-RMI å°†é˜»ç¢æ€§èƒ½ã€‚

å› æ­¤ï¼Œå°†å°çš„ iSets åˆå¹¶æˆä¸€ä¸ªå‰©ä½™é›†ã€‚å‰©ä½™é›†ä¸­çš„è§„åˆ™ä½¿ç”¨å¤–éƒ¨åˆ†ç±»å™¨è¿›è¡Œç´¢å¼•ã€‚æ¯ä¸ªæŸ¥è¯¢éƒ½æ˜¯åœ¨ RQ-RMI å’Œå¤–éƒ¨åˆ†ç±»å™¨ä¸Šè¿›è¡Œçš„ã€‚

NuevoMatch ä½œä¸ºå¤–éƒ¨åˆ†ç±»å™¨çš„åŠ é€Ÿå™¨ã€‚å¦‚æœä½¿ç”¨å‡ ä¸ªå¤§çš„ iSets è¦†ç›–è§„åˆ™é›†ï¼Œå¤–éƒ¨åˆ†ç±»å™¨éœ€è¦ç´¢å¼•ä¸€ä¸ªå°çš„å‰©ä½™é›†ï¼Œè¿™å°†ä¼šéå¸¸å¿«ã€‚

è¯„ä¼°(Â§5.3.1)æ˜¾ç¤ºï¼Œå¤§éƒ¨åˆ†è¯„ä¼°çš„è§„åˆ™é›†åªéœ€è¦ 2-3 ä¸ª iSets å°±å¯ä»¥è¦†ç›– 90% ä»¥ä¸Šçš„é«˜è¦†ç›–ç‡ã€‚

**Worst-case inputs**

æœ€åçš„æƒ…å†µï¼Œä¸€ä¸ªè§„åˆ™é›†éœ€è¦éå¸¸å¤šçš„ iSets æ‰èƒ½è¦†ç›–ã€‚

ä¸ºäº†ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œè€ƒè™‘å…·æœ‰ç²¾ç¡®åŒ¹é…çš„è§„åˆ™é›†çš„è§„åˆ™é›†å¤šæ ·æ€§çš„æ¦‚å¿µã€‚ä¸€ä¸ªå­—æ®µä¸­çš„è§„åˆ™é›†å¤šæ ·æ€§æ˜¯æŒ‡æ•´ä¸ªè§„åˆ™é›†ä¸­å”¯ä¸€å€¼çš„æ•°é‡é™¤ä»¥è§„åˆ™æ€»æ•°ã€‚

> *The rule-set diversity is an upper bound on the fraction of rules in the largest iSet of that field.*

ä½å¤šæ ·æ€§æ„å‘³ç€ä½¿ç”¨è¯¥å­—æ®µè¿›è¡Œ iSet åˆ†å‰²ä¼šå¯¼è‡´è¦†ç›–ç‡ä½ã€‚

ä¹Ÿå¯ä»¥è€ƒè™‘ä½¿ç”¨èŒƒå›´æ¥è¯†åˆ«çš„è§„åˆ™é›†ã€‚å®šä¹‰ rule-set centrality ä¸ºæ¯å¯¹è§„åˆ™é‡å çš„æœ€å¤§æ•°é‡ã€‚

> The rule-set centrality is a lower bound on the number of iSets required for full coverage.

è§„åˆ™é›†çš„å¤šæ ·æ€§ï¼ˆdiversityï¼‰å’Œä¸­å¿ƒæ€§ï¼ˆcentralityï¼‰æŒ‡æ ‡å¯ä»¥è¡¨æ˜ NuevoMatch åŠ é€Ÿè§„åˆ™é›†åˆ†ç±»çš„æ½œåŠ›ã€‚

è®ºæ–‡çš„ iSet åˆ†åŒºç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†ä¸èƒ½å¾ˆå¥½è¦†ç›–çš„è§„åˆ™ä¸å¯ä»¥è¦†ç›–çš„è§„åˆ™éš”ç¦»å¼€æ¥ï¼Œä»è€Œå°½å¯èƒ½åœ°åŠ é€Ÿå‰©ä½™åˆ†ç±»å™¨å¯¹ç»™å®šè§„åˆ™é›†çš„åˆ†ç±»ã€‚

### 3.8 æ•´åˆ Putting it all together



### 3.9 è§„åˆ™æ›´æ–° Rule Updates



## 4 å®ç°ç»†èŠ‚ IMPLEMENTATION DETAILS

























