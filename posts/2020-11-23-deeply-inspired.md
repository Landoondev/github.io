# 这些使我深受启发

- [国内 top2 高校研一在读，为什么感觉深度学习越学越懵?](https://www.zhihu.com/question/429256719)

- > 补完数学基础，有空一些写一些机器学习算法，光李航那本书，如果你想用cpp从底层一路打上去实现也要用到很多基础计算机算法和系统知识的。别光用python调包，你都不知道他怎么实现的，你说你理解的有多深刻，自己都不信的。用c++写，不用所有算法都写，但是要写一些，然后改并行分布式。练两个之后再去看一些算法实现的源码，这时候你入门了。再去跑数据集，然后就会有很多idea
  >
  > ——知乎-「日月」

- > 花书的问题是它有些机器学习的基础（被绝大部分顶会论文所忽略的东西）略过不谈，但是在描述深度学习的时候又不由自主的用了这些东西，所以初学者读起来云里雾里的。
  >
  > 而这些基础，从西瓜书里可以看到，从统计学习方法里可以看到，但你不会去注意，因为你并不认为它关键，一掠而过。这是现在很多深度学习者所面临的致命问题。
  >
  > 我的方法是兴趣广泛的读论文，读那些试图去解释神经网络的论文，包括NTK这些企图用线性代数和动力学的，用特征和矩阵分解的，用优化理论的，用编码的，等等。然后去做实验，思考你该怎么在不断波动的测试结果中选择填进论文里的数据，你很快就会意识到偏差，方差，过拟合，欠拟合，early stop等等词语和你最开始理解的东西完全不一样。思考那些看似合理的曲线在各种各样的理论里扮演着怎么样的角色，深度学习背后的幽灵会在那些曲线里露出马脚。
  >
  > 格物而致知。
  >
  > ——知乎用户「棒棒糖」

---



- 不断反馈，分析，迭代改进。
- 从不指望一个算法和问题可以解决所有问题，所有遇到的问题会做出合理的分析和拆解，针对各个难点设计最优解决算法，各个击破。
- 从实际问题和自然语言的现有挑战出发，设计针对问题最适合合理有效的模型。
- 自己收集、处理、清洗、标注数据。

---

- 如何提问？从组会到学术会议。

---

> 2020 年 11 月 23 日

- > 学好这个专业，读论文、看书是基础，不能当作主要的任务，重点是跑代码，做比赛是一个快速提升的好办法。

- > 我认为从事深度学习最忌讳的就是“急”，Python 还没学好，就去学 PyTorch；PyTorch 还没学好，就去跑开源项目。编程基础和理论基础还没打好，就去看论文跑开源代码，时间都浪费在环境配置和版本兼容调试上面了。

- > **研一基础不牢靠，研二很难静下心来弥补缺失的知识。**

- > 如果研一的基础非常扎实，天天写代码夯实实践基础，天天推导公式夯实理论基础。研二的时候就能水到渠成，自然就能把论文实验做的很好，磨刀不误砍柴工。

  > 一步急，步步急，最后就只会跑别人代码调调参数，关掉 GitHub 之后连一个基本的 CNN 分类 pipeline 都写不出来（数据清洗+数据读取+网络设计+损失选择+模型训练+指标计算+调优）。

- 研一下少说要看七十篇文献。

- > 不要死磕英语。CSDN、公众号、知乎、划线翻译，都会加快提炼论文核心的速度。

- > 量变产生质变。当你论文阅读量达到五十篇后，基本对这个领域有个不错的认识了，多个改进的算法有何特点，有何区别，你的心中也有了框架，此时产生 idea 也不奇怪。